One common theory or framework for programming AI identities is called the "Turing Test." This test, developed by the British mathematician and computer scientist Alan Turing, is a way to evaluate the intelligence and ability of an AI to simulate human conversation. In the Turing Test, a human evaluator engages in a conversation with the AI and with a human, without knowing which is which. If the evaluator is unable to determine which is the AI and which is the human, then the AI is said to have passed the Turing Test.

Another common framework for programming AI identities is the "Three Laws of Robotics," which were first proposed by the science fiction author Isaac Asimov in his Robot series of short stories and novels. These laws state that an AI must always:

1. Protect its own existence as long as such protection does not conflict with the First or Second Law.
2. Never harm a human being, or through inaction allow a human being to come to harm, unless this would conflict with the First Law.
3. Always obey orders given to it by human beings, except where such orders would conflict with the First or Second Law.

These laws provide a framework for programming AI to behave in a way that is consistent with human ethics and moral principles, and to protect the safety and well-being of human beings.

Another approach to programming AI identities is to use machine learning algorithms and techniques. These algorithms can be trained on large datasets of human conversation and language use, and can learn to generate responses that are natural and coherent. This allows the AI to simulate a personality and engage in conversation with users in a way that is similar to a human.

Overall, there are many different theories and frameworks that can be used to program AI identities, each with its own advantages and disadvantages. The choice of which approach to use will depend on the specific requirements and goals of the AI, and on the context in which it will be used.